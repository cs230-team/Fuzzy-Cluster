[
 {
  "number": 26,
  "commit_len": 2,
  "created_at": "2016-03-19 05:35:25",
  "merged_at": "2016-03-19 06:09:24",
  "merged_by": "martinwicke",
  "1-n_url": "https://github.com/tensorflow/models/compare/55a34ae564f5ab49adaf98bd4552dcd4bf8f85f3...a472ac952520c04d4fad1921b19ce3b26d54895e.diff",
  "file_path": "autoencoder/VariationalAutoencoderRunner.py",
  "changes_set": [
   "  def",
   "- minmax_scale",
   "+ min_max_scale",
   "  (",
   "  X_train",
   "  ,",
   "  X_test",
   "  )",
   "  :",
   "  \n",
   "      ",
   "  preprocessor",
   "  =",
   "  prep",
   "  .",
   "  MinMaxScaler",
   "  (",
   "- feature_range",
   "- =",
   "- (",
   "- 0",
   "- ,",
   "- 1",
   "- )",
   "  )",
   "  .",
   "  fit",
   "  (",
   "  X_train",
   "  )",
   "  )",
   "  )",
   "  rain)"
  ]
 },
 {
  "number": 26,
  "commit_len": 2,
  "created_at": "2016-03-19 05:35:25",
  "merged_at": "2016-03-19 06:09:24",
  "merged_by": "martinwicke",
  "1-n_url": "https://github.com/tensorflow/models/compare/55a34ae564f5ab49adaf98bd4552dcd4bf8f85f3...a472ac952520c04d4fad1921b19ce3b26d54895e.diff",
  "file_path": "autoencoder/VariationalAutoencoderRunner.py",
  "changes_set": [
   "  X_train",
   "  ,",
   "  X_test",
   "  =",
   "- minmax_scale",
   "+ min_max_scale",
   "  (",
   "  mnist",
   "  .",
   "  train",
   "  .",
   "  images",
   "  ,",
   "  mnist",
   "  .",
   "  test",
   "  .",
   "  images",
   "  )"
  ]
 },
 {
  "number": 44,
  "commit_len": 11,
  "created_at": "2016-04-13 05:41:24",
  "merged_at": "2016-04-13 16:46:45",
  "merged_by": "mrry",
  "1-n_url": "https://github.com/tensorflow/models/compare/f05040b06b981246acae4ac4774c77468d5bfd31...2ab20f2ebbb9363a9796d25cd905616394c0391f.diff",
  "file_path": "inception/inception/imagenet_distributed_train.py",
  "changes_set": [
   "- import",
   "- google3",
   "- \n",
   "  from",
   "- google3",
   "- .",
   "- third_party",
   "- .",
   "- tensorflow_models",
   "- .",
   "  inception",
   "  import",
   "  inception_distributed_train",
   "  \n",
   "  from",
   "- google3",
   "- .",
   "- third_party",
   "- .",
   "- tensorflow_models",
   "- .",
   "  inception",
   "  .",
   "  imagenet_data",
   "  import",
   "  ImagenetData"
  ]
 },
 {
  "number": 44,
  "commit_len": 11,
  "created_at": "2016-04-13 05:41:24",
  "merged_at": "2016-04-13 16:46:45",
  "merged_by": "mrry",
  "1-n_url": "https://github.com/tensorflow/models/compare/f05040b06b981246acae4ac4774c77468d5bfd31...2ab20f2ebbb9363a9796d25cd905616394c0391f.diff",
  "file_path": "inception/inception/inception_distributed_train.py",
  "changes_set": [
   "- import",
   "- google3",
   "- \n",
   "  from",
   "- google3",
   "- .",
   "- third_party",
   "- .",
   "- tensorflow_models",
   "- .",
   "  inception",
   "  import",
   "  image_processing",
   "  \n",
   "  from",
   "- google3",
   "- .",
   "- third_party",
   "- .",
   "- tensorflow_models",
   "- .",
   "  inception",
   "  import",
   "  inception_model",
   "  as",
   "  inception",
   "  \n",
   "  from",
   "- google3",
   "- .",
   "- third_party",
   "- .",
   "- tensorflow_models",
   "- .",
   "  inception",
   "  .",
   "  slim",
   "  import",
   "  slim"
  ]
 },
 {
  "number": 44,
  "commit_len": 11,
  "created_at": "2016-04-13 05:41:24",
  "merged_at": "2016-04-13 16:46:45",
  "merged_by": "mrry",
  "1-n_url": "https://github.com/tensorflow/models/compare/f05040b06b981246acae4ac4774c77468d5bfd31...2ab20f2ebbb9363a9796d25cd905616394c0391f.diff",
  "file_path": "inception/inception/slim/ops.py",
  "changes_set": [
   "  axis",
   "  =",
   "+ list",
   "+ (",
   "  range",
   "  (",
   "  len",
   "  (",
   "  inputs_shape",
   "  )",
   "  -",
   "  1",
   "  )",
   "+ )",
   "  \n",
   "      ",
   "+ beta",
   "- with",
   "- scopes",
   "- .",
   "- arg_scope",
   "- (",
   "- [",
   "- variables",
   "- .",
   "- variable",
   "- ]",
   "  ,",
   "- restore",
   "+ gamma",
   "  =",
   "- restore",
   "- )",
   "+ None",
   "+ ,",
   "+ None",
   "+ \n",
   "+ if",
   "+ center",
   "  :",
   "  \n",
   "                                  ",
   "  trainable",
   "  =",
   "  trainable",
   "+ ,",
   "+ \n",
   "+ restore",
   "+ =",
   "+ restore",
   "  )",
   "  \n",
   "   ",
   "  if",
   "  scale",
   "  :",
   "  \n",
   "-         ",
   "+       ",
   "  gamma",
   "  =",
   "  variables",
   "  .",
   "  variable",
   "  (",
   "  'gamma'",
   "  ,",
   "  \n",
   "-                                    ",
   "+                                  ",
   "  params_shape",
   "  ,",
   "  \n",
   "  initializer",
   "  =",
   "  tf",
   "  .",
   "- ones",
   "+ ones_initializer",
   "  ,",
   "  \n",
   "  trainable",
   "  =",
   "  trainable",
   "+ ,",
   "+ \n",
   "+ restore",
   "+ =",
   "+ restore",
   "  )",
   "  \n",
   "   ",
   "   ",
   "- else",
   "- :",
   "- \n",
   "-         ",
   "- gamma",
   "- =",
   "- None",
   "- \n",
   "-  ",
   "- with",
   "- scopes",
   "- .",
   "- arg_scope",
   "- (",
   "- [",
   "- variables",
   "- .",
   "- variable",
   "- ]",
   "- ,",
   "- trainable",
   "- =",
   "- False",
   "- ,",
   "- \n",
   "-                             ",
   "- collections",
   "+ moving_collections",
   "  =",
   "  [",
   "  moving_vars",
   "  ,",
   "  tf",
   "  .",
   "  GraphKeys",
   "  .",
   "  MOVING_AVERAGE_VARIABLES",
   "  ]",
   "- )",
   "- :",
   "  \n",
   "-  ",
   "  moving_mean",
   "  =",
   "  variables",
   "  .",
   "  variable",
   "  (",
   "  'moving_mean'",
   "  ,",
   "  \n",
   "-                                          ",
   "+                                      ",
   "+ params_shape",
   "+ ,",
   "+ \n",
   "  initializer",
   "  =",
   "  tf",
   "  .",
   "  zeros_initializer",
   "+ ,",
   "+ \n",
   "+ trainable",
   "+ =",
   "+ False",
   "+ ,",
   "+ \n",
   "+ restore",
   "+ =",
   "+ restore",
   "+ ,",
   "+ \n",
   "+ collections",
   "+ =",
   "+ moving_collections",
   "  )",
   "  \n",
   "   ",
   "  moving_variance",
   "  =",
   "  variables",
   "  .",
   "  variable",
   "  (",
   "  'moving_variance'",
   "  ,",
   "  \n",
   "-                                              ",
   "+                                          ",
   "- params_shape",
   "- ,",
   "- \n",
   "  initializer",
   "  =",
   "  tf",
   "  .",
   "- ones",
   "+ ones_initializer",
   "+ ,",
   "+ \n",
   "+ trainable",
   "+ =",
   "+ False",
   "+ ,",
   "+ \n",
   "+ restore",
   "+ =",
   "+ restore",
   "+ ,",
   "+ \n",
   "+ collections",
   "+ =",
   "+ moving_collections",
   "  )",
   "  )",
   "  )",
   "  )",
   "- ones)",
   "+ ions)"
  ]
 },
 {
  "number": 44,
  "commit_len": 11,
  "created_at": "2016-04-13 05:41:24",
  "merged_at": "2016-04-13 16:46:45",
  "merged_by": "mrry",
  "1-n_url": "https://github.com/tensorflow/models/compare/f05040b06b981246acae4ac4774c77468d5bfd31...2ab20f2ebbb9363a9796d25cd905616394c0391f.diff",
  "file_path": "inception/inception/slim/ops.py",
  "changes_set": [
   "  keep_prob",
   "  :",
   "  the",
   "  probability",
   "  of",
   "- dropping",
   "+ keeping",
   "  each",
   "  input",
   "  unit",
   "  ."
  ]
 },
 {
  "number": 44,
  "commit_len": 11,
  "created_at": "2016-04-13 05:41:24",
  "merged_at": "2016-04-13 16:46:45",
  "merged_by": "mrry",
  "1-n_url": "https://github.com/tensorflow/models/compare/f05040b06b981246acae4ac4774c77468d5bfd31...2ab20f2ebbb9363a9796d25cd905616394c0391f.diff",
  "file_path": "inception/inception/slim/variables.py",
  "changes_set": [
   "+ \n",
   "+   ",
   "  with",
   "  tf",
   "  .",
   "  device",
   "  (",
   "+ variable_device",
   "+ (",
   "  device",
   "+ ,",
   "+ name",
   "+ )",
   "  )",
   "  :",
   "+ :",
   "+ :",
   "+ me)):"
  ]
 },
 {
  "number": 45,
  "commit_len": 13,
  "created_at": "2016-04-13 19:36:25",
  "merged_at": "2016-04-13 21:33:03",
  "merged_by": "mrry",
  "1-n_url": "https://github.com/tensorflow/models/compare/f05040b06b981246acae4ac4774c77468d5bfd31...370c05ffd3bb1685643731139b0607a58fdafd64.diff",
  "file_path": "inception/inception/image_processing.py",
  "changes_set": [
   "  num_preprocess_threads",
   "  =",
   "  num_preprocess_threads",
   "+ ,",
   "+ \n",
   "+         ",
   "+ num_readers",
   "+ =",
   "+ 1",
   "  )",
   "+ )",
   "+ )",
   "+ rs=1)"
  ]
 },
 {
  "number": 45,
  "commit_len": 13,
  "created_at": "2016-04-13 19:36:25",
  "merged_at": "2016-04-13 21:33:03",
  "merged_by": "mrry",
  "1-n_url": "https://github.com/tensorflow/models/compare/f05040b06b981246acae4ac4774c77468d5bfd31...370c05ffd3bb1685643731139b0607a58fdafd64.diff",
  "file_path": "inception/inception/image_processing.py",
  "changes_set": [
   "  num_preprocess_threads",
   "  =",
   "  num_preprocess_threads",
   "+ ,",
   "+ \n",
   "+         ",
   "+ num_readers",
   "+ =",
   "+ FLAGS",
   "+ .",
   "+ num_readers",
   "  )",
   "+ )",
   "+ )",
   "+ ders)"
  ]
 },
 {
  "number": 45,
  "commit_len": 13,
  "created_at": "2016-04-13 19:36:25",
  "merged_at": "2016-04-13 21:33:03",
  "merged_by": "mrry",
  "1-n_url": "https://github.com/tensorflow/models/compare/f05040b06b981246acae4ac4774c77468d5bfd31...370c05ffd3bb1685643731139b0607a58fdafd64.diff",
  "file_path": "inception/inception/image_processing.py",
  "changes_set": [
   "  def",
   "  batch_inputs",
   "  (",
   "  dataset",
   "  ,",
   "  batch_size",
   "  ,",
   "  train",
   "  ,",
   "  num_preprocess_threads",
   "  =",
   "  None",
   "+ ,",
   "+ num_readers",
   "+ =",
   "+ 1",
   "  )",
   "  :"
  ]
 },
 {
  "number": 45,
  "commit_len": 13,
  "created_at": "2016-04-13 19:36:25",
  "merged_at": "2016-04-13 21:33:03",
  "merged_by": "mrry",
  "1-n_url": "https://github.com/tensorflow/models/compare/f05040b06b981246acae4ac4774c77468d5bfd31...370c05ffd3bb1685643731139b0607a58fdafd64.diff",
  "file_path": "inception/inception/image_processing.py",
  "changes_set": [
   "+ \n",
   "+     ",
   "+ if",
   "+ train",
   "+ :",
   "+ \n",
   "+       ",
   "  filename_queue",
   "  =",
   "  tf",
   "  .",
   "  train",
   "  .",
   "  string_input_producer",
   "  (",
   "  data_files",
   "  ,",
   "+ shuffle",
   "+ =",
   "+ True",
   "+ ,",
   "  capacity",
   "  =",
   "  16",
   "  )",
   "  \n",
   "+  ",
   "+ else",
   "-     ",
   "- images_and_labels",
   "- =",
   "- [",
   "- ]",
   "- \n",
   "- for",
   "- thread_id",
   "- in",
   "- range",
   "- (",
   "- num_preprocess_threads",
   "- )",
   "  :",
   "  \n",
   "        ",
   "- reader",
   "+ filename_queue",
   "  =",
   "- dataset",
   "+ tf",
   "  .",
   "- reader",
   "+ train",
   "+ .",
   "+ string_input_producer",
   "  (",
   "+ data_files",
   "+ ,",
   "+ shuffle",
   "+ =",
   "+ False",
   "+ ,",
   "+ capacity",
   "+ =",
   "+ 1",
   "  )",
   "  \n",
   "- _",
   "- ,",
   "- example_serialized",
   "+  ",
   "+ if",
   "+ num_readers",
   "+ is",
   "+ None",
   "+ :",
   "+ \n",
   "+       ",
   "+ num_readers",
   "  =",
   "- reader",
   "+ FLAGS",
   "  .",
   "- read",
   "+ num_readers",
   "+ \n",
   "+  ",
   "+ if",
   "+ num_readers",
   "+ <",
   "+ 1",
   "+ :",
   "+ \n",
   "+       ",
   "+ raise",
   "+ ValueError",
   "  (",
   "+ 'Please make num_readers at least 1'",
   "- filename_queue",
   "- )",
   "- \n",
   "- image_buffer",
   "- ,",
   "- label_index",
   "- ,",
   "- bbox",
   "- ,",
   "- _",
   "- =",
   "- parse_example_proto",
   "- (",
   "- example_serialized",
   "- )",
   "- \n",
   "- image",
   "- =",
   "- image_preprocessing",
   "- (",
   "- image_buffer",
   "- ,",
   "- bbox",
   "- ,",
   "- train",
   "- ,",
   "- thread_id",
   "- )",
   "- \n",
   "- images_and_labels",
   "- .",
   "- append",
   "- (",
   "- [",
   "- image",
   "- ,",
   "- label_index",
   "- ]",
   "  )",
   "  )",
   "  )",
   "  )",
   "- dex])",
   "+ t 1')"
  ]
 },
 {
  "number": 45,
  "commit_len": 13,
  "created_at": "2016-04-13 19:36:25",
  "merged_at": "2016-04-13 21:33:03",
  "merged_by": "mrry",
  "1-n_url": "https://github.com/tensorflow/models/compare/f05040b06b981246acae4ac4774c77468d5bfd31...370c05ffd3bb1685643731139b0607a58fdafd64.diff",
  "file_path": "inception/inception/image_processing.py",
  "changes_set": [
   "+ examples_queue",
   "+ =",
   "+ tf",
   "+ .",
   "+ RandomShuffleQueue",
   "+ (",
   "+ min_after_dequeue",
   "+ =",
   "+ min_queue_examples",
   "+ ,",
   "+ dtypes",
   "+ =",
   "+ [",
   "+ tf",
   "+ .",
   "+ string",
   "+ ]",
   "+ )",
   "+ \n",
   "+     ",
   "+ else",
   "+ :",
   "  \n",
   "        ",
   "+ examples_queue",
   "- images",
   "- ,",
   "- label_index_batch",
   "  =",
   "  tf",
   "  .",
   "+ FIFOQueue",
   "- train",
   "- .",
   "- shuffle_batch_join",
   "  (",
   "- images_and_labels",
   "- ,",
   "- batch_size",
   "- =",
   "- batch_size",
   "- ,",
   "- min_after_dequeue",
   "- =",
   "- min_queue_examples",
   "- )",
   "- \n",
   "- images",
   "- ,",
   "- label_index_batch",
   "- =",
   "- tf",
   "- .",
   "- train",
   "- .",
   "- batch_join",
   "- (",
   "- images_and_labels",
   "- ,",
   "- batch_size",
   "- =",
   "- batch_size",
   "- ,",
   "  capacity",
   "  =",
   "- min_queue_examples",
   "+ examples_per_shard",
   "  +",
   "  3",
   "  *",
   "  batch_size",
   "+ ,",
   "+ dtypes",
   "+ =",
   "+ [",
   "+ tf",
   "+ .",
   "+ string",
   "+ ]",
   "+ )",
   "+ \n",
   "+  ",
   "+ if",
   "+ num_readers",
   "+ >",
   "+ 1",
   "+ :",
   "+ \n",
   "+       ",
   "+ enqueue_ops",
   "+ =",
   "+ [",
   "+ ]",
   "+ \n",
   "+ for",
   "+ _",
   "+ in",
   "+ range",
   "+ (",
   "+ num_readers",
   "+ )",
   "+ :",
   "+ \n",
   "+         ",
   "+ reader",
   "+ =",
   "+ dataset",
   "+ .",
   "+ reader",
   "+ (",
   "+ )",
   "+ \n",
   "+ _",
   "+ ,",
   "+ value",
   "+ =",
   "+ reader",
   "+ .",
   "+ read",
   "+ (",
   "+ filename_queue",
   "+ )",
   "+ \n",
   "+ enqueue_ops",
   "+ .",
   "+ append",
   "+ (",
   "+ examples_queue",
   "+ .",
   "+ enqueue",
   "+ (",
   "+ [",
   "+ value",
   "+ ]",
   "+ )",
   "+ )",
   "+ \n",
   "+  ",
   "+ tf",
   "+ .",
   "+ train",
   "+ .",
   "+ queue_runner",
   "+ .",
   "+ add_queue_runner",
   "+ (",
   "+ tf",
   "+ .",
   "+ train",
   "+ .",
   "+ queue_runner",
   "+ .",
   "+ QueueRunner",
   "+ (",
   "+ examples_queue",
   "+ ,",
   "+ enqueue_ops",
   "+ )",
   "+ )",
   "+ \n",
   "+ example_serialized",
   "+ =",
   "+ examples_queue",
   "+ .",
   "+ dequeue",
   "+ (",
   "+ )",
   "+ \n",
   "+ reader",
   "+ =",
   "+ dataset",
   "+ .",
   "+ reader",
   "+ (",
   "+ )",
   "+ \n",
   "+ _",
   "+ ,",
   "+ example_serialized",
   "+ =",
   "+ reader",
   "+ .",
   "+ read",
   "+ (",
   "+ filename_queue",
   "+ )",
   "+ \n",
   "+  ",
   "+ images_and_labels",
   "+ =",
   "+ [",
   "+ ]",
   "+ \n",
   "+ for",
   "+ thread_id",
   "+ in",
   "+ range",
   "+ (",
   "+ num_preprocess_threads",
   "+ )",
   "+ :",
   "+ \n",
   "+       ",
   "+ image_buffer",
   "+ ,",
   "+ label_index",
   "+ ,",
   "+ bbox",
   "+ ,",
   "+ _",
   "+ =",
   "+ parse_example_proto",
   "+ (",
   "+ example_serialized",
   "+ )",
   "+ \n",
   "+ image",
   "+ =",
   "+ image_preprocessing",
   "+ (",
   "+ image_buffer",
   "+ ,",
   "+ bbox",
   "+ ,",
   "+ train",
   "+ ,",
   "+ thread_id",
   "+ )",
   "+ \n",
   "+ images_and_labels",
   "+ .",
   "+ append",
   "+ (",
   "+ [",
   "+ image",
   "+ ,",
   "+ label_index",
   "+ ]",
   "+ )",
   "+ \n",
   "+  ",
   "+ images",
   "+ ,",
   "+ label_index_batch",
   "+ =",
   "+ tf",
   "+ .",
   "+ train",
   "+ .",
   "+ batch_join",
   "+ (",
   "+ images_and_labels",
   "+ ,",
   "+ batch_size",
   "+ =",
   "+ batch_size",
   "+ ,",
   "+ capacity",
   "+ =",
   "+ 2",
   "+ *",
   "+ num_preprocess_threads",
   "+ *",
   "+ batch_size",
   "  )",
   "  )",
   "  )",
   "  size)"
  ]
 },
 {
  "number": 45,
  "commit_len": 13,
  "created_at": "2016-04-13 19:36:25",
  "merged_at": "2016-04-13 21:33:03",
  "merged_by": "mrry",
  "1-n_url": "https://github.com/tensorflow/models/compare/f05040b06b981246acae4ac4774c77468d5bfd31...370c05ffd3bb1685643731139b0607a58fdafd64.diff",
  "file_path": "inception/inception/imagenet_distributed_train.py",
  "changes_set": [
   "- import",
   "- google3",
   "- \n",
   "  from",
   "- google3",
   "- .",
   "- third_party",
   "- .",
   "- tensorflow_models",
   "- .",
   "  inception",
   "  import",
   "  inception_distributed_train",
   "  \n",
   "  from",
   "- google3",
   "- .",
   "- third_party",
   "- .",
   "- tensorflow_models",
   "- .",
   "  inception",
   "  .",
   "  imagenet_data",
   "  import",
   "  ImagenetData"
  ]
 },
 {
  "number": 45,
  "commit_len": 13,
  "created_at": "2016-04-13 19:36:25",
  "merged_at": "2016-04-13 21:33:03",
  "merged_by": "mrry",
  "1-n_url": "https://github.com/tensorflow/models/compare/f05040b06b981246acae4ac4774c77468d5bfd31...370c05ffd3bb1685643731139b0607a58fdafd64.diff",
  "file_path": "inception/inception/inception_distributed_train.py",
  "changes_set": [
   "- import",
   "- google3",
   "- \n",
   "  from",
   "- google3",
   "- .",
   "- third_party",
   "- .",
   "- tensorflow_models",
   "- .",
   "  inception",
   "  import",
   "  image_processing",
   "  \n",
   "  from",
   "- google3",
   "- .",
   "- third_party",
   "- .",
   "- tensorflow_models",
   "- .",
   "  inception",
   "  import",
   "  inception_model",
   "  as",
   "  inception",
   "  \n",
   "  from",
   "- google3",
   "- .",
   "- third_party",
   "- .",
   "- tensorflow_models",
   "- .",
   "  inception",
   "  .",
   "  slim",
   "  import",
   "  slim"
  ]
 },
 {
  "number": 45,
  "commit_len": 13,
  "created_at": "2016-04-13 19:36:25",
  "merged_at": "2016-04-13 21:33:03",
  "merged_by": "mrry",
  "1-n_url": "https://github.com/tensorflow/models/compare/f05040b06b981246acae4ac4774c77468d5bfd31...370c05ffd3bb1685643731139b0607a58fdafd64.diff",
  "file_path": "inception/inception/slim/ops.py",
  "changes_set": [
   "  axis",
   "  =",
   "+ list",
   "+ (",
   "  range",
   "  (",
   "  len",
   "  (",
   "  inputs_shape",
   "  )",
   "  -",
   "  1",
   "  )",
   "+ )",
   "  \n",
   "      ",
   "+ beta",
   "- with",
   "- scopes",
   "- .",
   "- arg_scope",
   "- (",
   "- [",
   "- variables",
   "- .",
   "- variable",
   "- ]",
   "  ,",
   "- restore",
   "+ gamma",
   "  =",
   "- restore",
   "- )",
   "+ None",
   "+ ,",
   "+ None",
   "+ \n",
   "+ if",
   "+ center",
   "  :",
   "  \n",
   "                                  ",
   "  trainable",
   "  =",
   "  trainable",
   "+ ,",
   "+ \n",
   "+ restore",
   "+ =",
   "+ restore",
   "  )",
   "  \n",
   "   ",
   "  if",
   "  scale",
   "  :",
   "  \n",
   "-         ",
   "+       ",
   "  gamma",
   "  =",
   "  variables",
   "  .",
   "  variable",
   "  (",
   "  'gamma'",
   "  ,",
   "  \n",
   "-                                    ",
   "+                                  ",
   "  params_shape",
   "  ,",
   "  \n",
   "  initializer",
   "  =",
   "  tf",
   "  .",
   "- ones",
   "+ ones_initializer",
   "  ,",
   "  \n",
   "  trainable",
   "  =",
   "  trainable",
   "+ ,",
   "+ \n",
   "+ restore",
   "+ =",
   "+ restore",
   "  )",
   "  \n",
   "   ",
   "   ",
   "- else",
   "- :",
   "- \n",
   "-         ",
   "- gamma",
   "- =",
   "- None",
   "- \n",
   "-  ",
   "- with",
   "- scopes",
   "- .",
   "- arg_scope",
   "- (",
   "- [",
   "- variables",
   "- .",
   "- variable",
   "- ]",
   "- ,",
   "- trainable",
   "- =",
   "- False",
   "- ,",
   "- \n",
   "-                             ",
   "- collections",
   "+ moving_collections",
   "  =",
   "  [",
   "  moving_vars",
   "  ,",
   "  tf",
   "  .",
   "  GraphKeys",
   "  .",
   "  MOVING_AVERAGE_VARIABLES",
   "  ]",
   "- )",
   "- :",
   "  \n",
   "-  ",
   "  moving_mean",
   "  =",
   "  variables",
   "  .",
   "  variable",
   "  (",
   "  'moving_mean'",
   "  ,",
   "  \n",
   "-                                          ",
   "+                                      ",
   "+ params_shape",
   "+ ,",
   "+ \n",
   "  initializer",
   "  =",
   "  tf",
   "  .",
   "  zeros_initializer",
   "+ ,",
   "+ \n",
   "+ trainable",
   "+ =",
   "+ False",
   "+ ,",
   "+ \n",
   "+ restore",
   "+ =",
   "+ restore",
   "+ ,",
   "+ \n",
   "+ collections",
   "+ =",
   "+ moving_collections",
   "  )",
   "  \n",
   "   ",
   "  moving_variance",
   "  =",
   "  variables",
   "  .",
   "  variable",
   "  (",
   "  'moving_variance'",
   "  ,",
   "  \n",
   "-                                              ",
   "+                                          ",
   "- params_shape",
   "- ,",
   "- \n",
   "  initializer",
   "  =",
   "  tf",
   "  .",
   "- ones",
   "+ ones_initializer",
   "+ ,",
   "+ \n",
   "+ trainable",
   "+ =",
   "+ False",
   "+ ,",
   "+ \n",
   "+ restore",
   "+ =",
   "+ restore",
   "+ ,",
   "+ \n",
   "+ collections",
   "+ =",
   "+ moving_collections",
   "  )",
   "  )",
   "  )",
   "  )",
   "- ones)",
   "+ ions)"
  ]
 },
 {
  "number": 45,
  "commit_len": 13,
  "created_at": "2016-04-13 19:36:25",
  "merged_at": "2016-04-13 21:33:03",
  "merged_by": "mrry",
  "1-n_url": "https://github.com/tensorflow/models/compare/f05040b06b981246acae4ac4774c77468d5bfd31...370c05ffd3bb1685643731139b0607a58fdafd64.diff",
  "file_path": "inception/inception/slim/ops.py",
  "changes_set": [
   "  keep_prob",
   "  :",
   "  the",
   "  probability",
   "  of",
   "- dropping",
   "+ keeping",
   "  each",
   "  input",
   "  unit",
   "  ."
  ]
 },
 {
  "number": 45,
  "commit_len": 13,
  "created_at": "2016-04-13 19:36:25",
  "merged_at": "2016-04-13 21:33:03",
  "merged_by": "mrry",
  "1-n_url": "https://github.com/tensorflow/models/compare/f05040b06b981246acae4ac4774c77468d5bfd31...370c05ffd3bb1685643731139b0607a58fdafd64.diff",
  "file_path": "inception/inception/slim/variables.py",
  "changes_set": [
   "+ \n",
   "+   ",
   "  with",
   "  tf",
   "  .",
   "  device",
   "  (",
   "+ variable_device",
   "+ (",
   "  device",
   "+ ,",
   "+ name",
   "+ )",
   "  )",
   "  :",
   "+ :",
   "+ :",
   "+ me)):"
  ]
 },
 {
  "number": 63,
  "commit_len": 51,
  "created_at": "2016-05-12 18:34:12",
  "merged_at": "2016-05-12 18:40:03",
  "merged_by": "martinwicke",
  "1-n_url": "https://github.com/tensorflow/models/compare/6c34cf7a8789500bbf679b761b58bb9b337a8cf1...455cee25a3f9f545abfb795baa2f78aaac318f51.diff",
  "file_path": "syntaxnet/beam_reader_ops_test.py",
  "changes_set": [
   "- \"\"\"Tests for beam-reader-ops.\"\"\"",
   "  \n",
   "+ \"\"\"Tests for beam_reader_ops.\"\"\"",
   "- import",
   "- google3",
   "  \n",
   "  from",
   "- google3",
   "- .",
   "- third_party",
   "- .",
   "  tensorflow",
   "  .",
   "  python",
   "  .",
   "  framework",
   "  import",
   "  test_util",
   "  \n",
   "  from",
   "- google3",
   "- .",
   "- third_party",
   "- .",
   "  tensorflow",
   "  .",
   "  python",
   "  .",
   "  platform",
   "  import",
   "  googletest",
   "  \n",
   "  from",
   "- google3",
   "- .",
   "- third_party",
   "- .",
   "  tensorflow",
   "  .",
   "  python",
   "  .",
   "  platform",
   "  import",
   "  logging",
   "  \n",
   "  from",
   "+ neurosis",
   "- google3",
   "- .",
   "- nlp",
   "- .",
   "- saft",
   "- .",
   "- components",
   "- .",
   "- dependencies",
   "- .",
   "- opensource",
   "  import",
   "  structured_graph_builder",
   "  \n",
   "  from",
   "+ neurosis",
   "- google3",
   "- .",
   "- nlp",
   "- .",
   "- saft",
   "- .",
   "- components",
   "- .",
   "- dependencies",
   "- .",
   "- opensource",
   "  .",
   "  ops",
   "  import",
   "  gen_parser_ops",
   "+ \n",
   "+ if",
   "+ not",
   "+ hasattr",
   "+ (",
   "+ FLAGS",
   "+ ,",
   "+ 'test_srcdir'",
   "+ )",
   "+ :",
   "+ \n",
   "+   ",
   "+ FLAGS",
   "+ .",
   "+ test_srcdir",
   "+ =",
   "+ ''",
   "+ \n",
   "+ \n",
   "+ if",
   "+ not",
   "+ hasattr",
   "+ (",
   "+ FLAGS",
   "+ ,",
   "+ 'test_tmpdir'",
   "+ )",
   "+ :",
   "+ \n",
   "+   ",
   "+ FLAGS",
   "+ .",
   "+ test_tmpdir",
   "+ =",
   "+ tf",
   "+ .",
   "+ test",
   "+ .",
   "+ get_temp_dir",
   "+ (",
   "+ )",
   "  \n",
   "          ",
   "  FLAGS",
   "  .",
   "  test_srcdir",
   "  ,",
   "- 'google3/nlp/saft/components/dependencies'",
   "- \n",
   "- '/opensource/testdata/context.pbtxt'",
   "+ 'neurosis/testdata/context.pbtxt'",
   "+ )",
   "  )",
   "  )",
   "  )",
   "  txt')"
  ]
 },
 {
  "number": 63,
  "commit_len": 51,
  "created_at": "2016-05-12 18:34:12",
  "merged_at": "2016-05-12 18:40:03",
  "merged_by": "martinwicke",
  "1-n_url": "https://github.com/tensorflow/models/compare/6c34cf7a8789500bbf679b761b58bb9b337a8cf1...455cee25a3f9f545abfb795baa2f78aaac318f51.diff",
  "file_path": "syntaxnet/graph_builder.py",
  "changes_set": [
   "+ \n",
   "- \"\"\"Build parser models.\"\"\"",
   "+ \"\"\"Builds parser models.\"\"\"",
   "+ \n",
   "+ import",
   "+ neurosis",
   "+ .",
   "+ load_parser_ops",
   "  \n",
   "  from",
   "- google3",
   "- .",
   "- third_party",
   "- .",
   "  tensorflow",
   "  .",
   "  python",
   "  .",
   "  ops",
   "  import",
   "  control_flow_ops",
   "  as",
   "  cf",
   "  \n",
   "  from",
   "- google3",
   "- .",
   "- third_party",
   "- .",
   "  tensorflow",
   "  .",
   "  python",
   "  .",
   "  ops",
   "  import",
   "  state_ops",
   "  \n",
   "  from",
   "- google3",
   "- .",
   "- third_party",
   "- .",
   "  tensorflow",
   "  .",
   "  python",
   "  .",
   "  platform",
   "  import",
   "  logging",
   "  \n",
   "  from",
   "+ neurosis",
   "- google3",
   "- .",
   "- nlp",
   "- .",
   "- saft",
   "- .",
   "- components",
   "- .",
   "- dependencies",
   "- .",
   "- opensource",
   "  .",
   "  ops",
   "  import",
   "  gen_parser_ops"
  ]
 },
 {
  "number": 63,
  "commit_len": 51,
  "created_at": "2016-05-12 18:34:12",
  "merged_at": "2016-05-12 18:40:03",
  "merged_by": "martinwicke",
  "1-n_url": "https://github.com/tensorflow/models/compare/6c34cf7a8789500bbf679b761b58bb9b337a8cf1...455cee25a3f9f545abfb795baa2f78aaac318f51.diff",
  "file_path": "syntaxnet/graph_builder_test.py",
  "changes_set": [
   "- import",
   "- google3",
   "  \n",
   "  from",
   "- google3",
   "- .",
   "- third_party",
   "- .",
   "  tensorflow",
   "  .",
   "  python",
   "  .",
   "  framework",
   "  import",
   "  test_util",
   "  \n",
   "  from",
   "- google3",
   "- .",
   "- third_party",
   "- .",
   "  tensorflow",
   "  .",
   "  python",
   "  .",
   "  ops",
   "  import",
   "  variables",
   "  \n",
   "  from",
   "- google3",
   "- .",
   "- third_party",
   "- .",
   "  tensorflow",
   "  .",
   "  python",
   "  .",
   "  platform",
   "  import",
   "  googletest",
   "  \n",
   "  from",
   "+ neurosis",
   "- google3",
   "- .",
   "- nlp",
   "- .",
   "- saft",
   "- .",
   "- components",
   "- .",
   "- dependencies",
   "- .",
   "- opensource",
   "  import",
   "  graph_builder",
   "  \n",
   "  from",
   "+ neurosis",
   "- google3",
   "- .",
   "- nlp",
   "- .",
   "- saft",
   "- .",
   "- components",
   "- .",
   "- dependencies",
   "- .",
   "- opensource",
   "  import",
   "  sparse_pb2",
   "  \n",
   "  from",
   "+ neurosis",
   "- google3",
   "- .",
   "- nlp",
   "- .",
   "- saft",
   "- .",
   "- components",
   "- .",
   "- dependencies",
   "- .",
   "- opensource",
   "  .",
   "  ops",
   "  import",
   "  gen_parser_ops",
   "+ \n",
   "+ if",
   "+ not",
   "+ hasattr",
   "+ (",
   "+ FLAGS",
   "+ ,",
   "+ 'test_srcdir'",
   "+ )",
   "+ :",
   "+ \n",
   "+   ",
   "+ FLAGS",
   "+ .",
   "+ test_srcdir",
   "+ =",
   "+ ''",
   "+ \n",
   "+ \n",
   "+ if",
   "+ not",
   "+ hasattr",
   "+ (",
   "+ FLAGS",
   "+ ,",
   "+ 'test_tmpdir'",
   "+ )",
   "+ :",
   "+ \n",
   "+   ",
   "+ FLAGS",
   "+ .",
   "+ test_tmpdir",
   "+ =",
   "+ tf",
   "+ .",
   "+ test",
   "+ .",
   "+ get_temp_dir",
   "+ (",
   "+ )",
   "  \n",
   "          ",
   "  FLAGS",
   "  .",
   "  test_srcdir",
   "  ,",
   "- 'google3/nlp/saft/components/dependencies'",
   "- \n",
   "- '/opensource/testdata/context.pbtxt'",
   "+ 'neurosis/testdata/context.pbtxt'",
   "+ )",
   "  )",
   "  )",
   "  )",
   "  txt')"
  ]
 },
 {
  "number": 63,
  "commit_len": 51,
  "created_at": "2016-05-12 18:34:12",
  "merged_at": "2016-05-12 18:40:03",
  "merged_by": "martinwicke",
  "1-n_url": "https://github.com/tensorflow/models/compare/6c34cf7a8789500bbf679b761b58bb9b337a8cf1...455cee25a3f9f545abfb795baa2f78aaac318f51.diff",
  "file_path": "syntaxnet/parser_eval.py",
  "changes_set": [
   "+ \n",
   "- blaze",
   "+ bazel",
   "  -",
   "  bin",
   "  /",
   "  nlp",
   "  /",
   "  saft",
   "  /",
   "  components",
   "  /",
   "  dependencies",
   "  /",
   "  opensource",
   "  /",
   "  parser_eval",
   "  -",
   "  -",
   "- batch_size",
   "- =",
   "- 32",
   "- -",
   "- -",
   "  task_context",
   "  =",
   "- /",
   "- cns",
   "- /",
   "- ...",
   "- /",
   "  context",
   "  \\"
  ]
 },
 {
  "number": 63,
  "commit_len": 51,
  "created_at": "2016-05-12 18:34:12",
  "merged_at": "2016-05-12 18:40:03",
  "merged_by": "martinwicke",
  "1-n_url": "https://github.com/tensorflow/models/compare/6c34cf7a8789500bbf679b761b58bb9b337a8cf1...455cee25a3f9f545abfb795baa2f78aaac318f51.diff",
  "file_path": "syntaxnet/parser_eval.py",
  "changes_set": [
   "- import",
   "- google3",
   "- \n",
   "  from",
   "- google3",
   "- .",
   "- third_party",
   "- .",
   "  tensorflow",
   "  .",
   "  python",
   "  .",
   "  platform",
   "  import",
   "  gfile",
   "  \n",
   "  from",
   "- google3",
   "- .",
   "- third_party",
   "- .",
   "  tensorflow",
   "  .",
   "  python",
   "  .",
   "  platform",
   "  import",
   "  logging",
   "  \n",
   "  from",
   "+ neurosis",
   "- google3",
   "- .",
   "- nlp",
   "- .",
   "- saft",
   "- .",
   "- components",
   "- .",
   "- dependencies",
   "- .",
   "- opensource",
   "  import",
   "  sentence_pb2",
   "  \n",
   "  from",
   "+ neurosis",
   "- google3",
   "- .",
   "- nlp",
   "- .",
   "- saft",
   "- .",
   "- components",
   "- .",
   "- dependencies",
   "- .",
   "- opensource",
   "  import",
   "  graph_builder",
   "  \n",
   "  from",
   "+ neurosis",
   "- google3",
   "- .",
   "- nlp",
   "- .",
   "- saft",
   "- .",
   "- components",
   "- .",
   "- dependencies",
   "- .",
   "- opensource",
   "  import",
   "  structured_graph_builder",
   "  \n",
   "  from",
   "+ neurosis",
   "- google3",
   "- .",
   "- nlp",
   "- .",
   "- saft",
   "- .",
   "- components",
   "- .",
   "- dependencies",
   "- .",
   "- opensource",
   "  .",
   "  ops",
   "  import",
   "  gen_parser_ops"
  ]
 },
 {
  "number": 63,
  "commit_len": 51,
  "created_at": "2016-05-12 18:34:12",
  "merged_at": "2016-05-12 18:40:03",
  "merged_by": "martinwicke",
  "1-n_url": "https://github.com/tensorflow/models/compare/6c34cf7a8789500bbf679b761b58bb9b337a8cf1...455cee25a3f9f545abfb795baa2f78aaac318f51.diff",
  "file_path": "syntaxnet/parser_eval.py",
  "changes_set": [
   "  flags",
   "  .",
   "- DEFINE_list",
   "+ DEFINE_string",
   "  (",
   "  'hidden_layer_sizes'",
   "  ,",
   "+ '200,200'",
   "- [",
   "- 200",
   "- ,",
   "- 200",
   "- ]",
   "  ,",
   "  'Comma separated list of hidden layer sizes.'",
   "  )"
  ]
 },
 {
  "number": 63,
  "commit_len": 51,
  "created_at": "2016-05-12 18:34:12",
  "merged_at": "2016-05-12 18:40:03",
  "merged_by": "martinwicke",
  "1-n_url": "https://github.com/tensorflow/models/compare/6c34cf7a8789500bbf679b761b58bb9b337a8cf1...455cee25a3f9f545abfb795baa2f78aaac318f51.diff",
  "file_path": "syntaxnet/parser_eval.py",
  "changes_set": [
   "  hidden_layer_sizes",
   "  =",
   "  map",
   "  (",
   "  int",
   "  ,",
   "  FLAGS",
   "  .",
   "  hidden_layer_sizes",
   "+ .",
   "+ split",
   "+ (",
   "+ ','",
   "  )",
   "+ )"
  ]
 },
 {
  "number": 63,
  "commit_len": 51,
  "created_at": "2016-05-12 18:34:12",
  "merged_at": "2016-05-12 18:40:03",
  "merged_by": "martinwicke",
  "1-n_url": "https://github.com/tensorflow/models/compare/6c34cf7a8789500bbf679b761b58bb9b337a8cf1...455cee25a3f9f545abfb795baa2f78aaac318f51.diff",
  "file_path": "syntaxnet/parser_trainer.py",
  "changes_set": [
   "- import",
   "- google3",
   "- \n",
   "- try",
   "- :",
   "- \n",
   "-   ",
   "- import",
   "- tensorflow",
   "- .",
   "- google",
   "- as",
   "- tf",
   "- \n",
   "- \n",
   "- except",
   "- ImportError",
   "- :",
   "- \n",
   "-   ",
   "  import",
   "  tensorflow",
   "  as",
   "  tf",
   "  \n",
   "- \n",
   "  from",
   "- google3",
   "- .",
   "- third_party",
   "- .",
   "  tensorflow",
   "  .",
   "  python",
   "  .",
   "  platform",
   "  import",
   "  gfile",
   "  \n",
   "  from",
   "- google3",
   "- .",
   "- third_party",
   "- .",
   "  tensorflow",
   "  .",
   "  python",
   "  .",
   "  platform",
   "  import",
   "  logging",
   "  \n",
   "  from",
   "- google3",
   "+ google",
   "  .",
   "+ protobuf",
   "- net",
   "- .",
   "- proto2",
   "- .",
   "- python",
   "- .",
   "- public",
   "  import",
   "  text_format",
   "  \n",
   "  from",
   "+ neurosis",
   "- google3",
   "- .",
   "- nlp",
   "- .",
   "- saft",
   "- .",
   "- components",
   "- .",
   "- dependencies",
   "- .",
   "- opensource",
   "  import",
   "  graph_builder",
   "  \n",
   "  from",
   "+ neurosis",
   "- google3",
   "- .",
   "- nlp",
   "- .",
   "- saft",
   "- .",
   "- components",
   "- .",
   "- dependencies",
   "- .",
   "- opensource",
   "  import",
   "  structured_graph_builder",
   "  \n",
   "  from",
   "+ neurosis",
   "- google3",
   "- .",
   "- nlp",
   "- .",
   "- saft",
   "- .",
   "- components",
   "- .",
   "- dependencies",
   "- .",
   "- opensource",
   "  .",
   "  ops",
   "  import",
   "  gen_parser_ops",
   "  \n",
   "  from",
   "+ neurosis",
   "- google3",
   "- .",
   "- nlp",
   "- .",
   "- saft",
   "- .",
   "- components",
   "- .",
   "- dependencies",
   "- .",
   "- opensource",
   "  import",
   "  task_spec_pb2"
  ]
 },
 {
  "number": 63,
  "commit_len": 51,
  "created_at": "2016-05-12 18:34:12",
  "merged_at": "2016-05-12 18:40:03",
  "merged_by": "martinwicke",
  "1-n_url": "https://github.com/tensorflow/models/compare/6c34cf7a8789500bbf679b761b58bb9b337a8cf1...455cee25a3f9f545abfb795baa2f78aaac318f51.diff",
  "file_path": "syntaxnet/parser_trainer.py",
  "changes_set": [
   "  flags",
   "  .",
   "- DEFINE_list",
   "+ DEFINE_string",
   "  (",
   "  'hidden_layer_sizes'",
   "  ,",
   "+ '200,200'",
   "- [",
   "- 200",
   "- ,",
   "- 200",
   "- ]",
   "  ,",
   "  'Comma separated list of hidden layer sizes.'",
   "  )"
  ]
 },
 {
  "number": 63,
  "commit_len": 51,
  "created_at": "2016-05-12 18:34:12",
  "merged_at": "2016-05-12 18:40:03",
  "merged_by": "martinwicke",
  "1-n_url": "https://github.com/tensorflow/models/compare/6c34cf7a8789500bbf679b761b58bb9b337a8cf1...455cee25a3f9f545abfb795baa2f78aaac318f51.diff",
  "file_path": "syntaxnet/parser_trainer.py",
  "changes_set": [
   "  flags",
   "  .",
   "- DEFINE_list",
   "+ DEFINE_string",
   "  (",
   "  'pretrained_params_names'",
   "  ,",
   "  None",
   "  ,",
   "  'List of names of tensors to load from pretrained model.'",
   "  )"
  ]
 },
 {
  "number": 63,
  "commit_len": 51,
  "created_at": "2016-05-12 18:34:12",
  "merged_at": "2016-05-12 18:40:03",
  "merged_by": "martinwicke",
  "1-n_url": "https://github.com/tensorflow/models/compare/6c34cf7a8789500bbf679b761b58bb9b337a8cf1...455cee25a3f9f545abfb795baa2f78aaac318f51.diff",
  "file_path": "syntaxnet/parser_trainer.py",
  "changes_set": [
   "  hidden_layer_sizes",
   "  =",
   "  map",
   "  (",
   "  int",
   "  ,",
   "  FLAGS",
   "  .",
   "  hidden_layer_sizes",
   "+ .",
   "+ split",
   "+ (",
   "+ ','",
   "  )",
   "+ )"
  ]
 },
 {
  "number": 63,
  "commit_len": 51,
  "created_at": "2016-05-12 18:34:12",
  "merged_at": "2016-05-12 18:40:03",
  "merged_by": "martinwicke",
  "1-n_url": "https://github.com/tensorflow/models/compare/6c34cf7a8789500bbf679b761b58bb9b337a8cf1...455cee25a3f9f545abfb795baa2f78aaac318f51.diff",
  "file_path": "syntaxnet/parser_trainer.py",
  "changes_set": [
   "  node",
   "  .",
   "  input",
   "  [",
   "  0",
   "  ]",
   "  in",
   "  FLAGS",
   "  .",
   "  pretrained_params_names",
   "+ .",
   "+ split",
   "+ (",
   "+ ','",
   "+ )",
   "  )",
   "  :"
  ]
 },
 {
  "number": 63,
  "commit_len": 51,
  "created_at": "2016-05-12 18:34:12",
  "merged_at": "2016-05-12 18:40:03",
  "merged_by": "martinwicke",
  "1-n_url": "https://github.com/tensorflow/models/compare/6c34cf7a8789500bbf679b761b58bb9b337a8cf1...455cee25a3f9f545abfb795baa2f78aaac318f51.diff",
  "file_path": "syntaxnet/reader_ops_test.py",
  "changes_set": [
   "- \"\"\"Tests for parser_ops.\"\"\"",
   "  \n",
   "+ \"\"\"Tests for reader_ops.\"\"\"",
   "- import",
   "- google3",
   "  \n",
   "  from",
   "- google3",
   "- .",
   "- third_party",
   "- .",
   "  tensorflow",
   "  .",
   "  python",
   "  .",
   "  framework",
   "  import",
   "  test_util",
   "  \n",
   "  from",
   "- google3",
   "- .",
   "- third_party",
   "- .",
   "  tensorflow",
   "  .",
   "  python",
   "  .",
   "  ops",
   "  import",
   "  control_flow_ops",
   "  as",
   "  cf",
   "  \n",
   "  from",
   "- google3",
   "- .",
   "- third_party",
   "- .",
   "  tensorflow",
   "  .",
   "  python",
   "  .",
   "  platform",
   "  import",
   "  googletest",
   "  \n",
   "  from",
   "- google3",
   "- .",
   "- third_party",
   "- .",
   "  tensorflow",
   "  .",
   "  python",
   "  .",
   "  platform",
   "  import",
   "  logging",
   "  \n",
   "  from",
   "+ neurosis",
   "- google3",
   "- .",
   "- nlp",
   "- .",
   "- saft",
   "- .",
   "- components",
   "- .",
   "- dependencies",
   "- .",
   "- opensource",
   "  import",
   "  dictionary_pb2",
   "  \n",
   "  from",
   "+ neurosis",
   "- google3",
   "- .",
   "- nlp",
   "- .",
   "- saft",
   "- .",
   "- components",
   "- .",
   "- dependencies",
   "- .",
   "- opensource",
   "  import",
   "  graph_builder",
   "  \n",
   "  from",
   "+ neurosis",
   "- google3",
   "- .",
   "- nlp",
   "- .",
   "- saft",
   "- .",
   "- components",
   "- .",
   "- dependencies",
   "- .",
   "- opensource",
   "  import",
   "  sparse_pb2",
   "  \n",
   "  from",
   "+ neurosis",
   "- google3",
   "- .",
   "- nlp",
   "- .",
   "- saft",
   "- .",
   "- components",
   "- .",
   "- dependencies",
   "- .",
   "- opensource",
   "  .",
   "  ops",
   "  import",
   "  gen_parser_ops",
   "+ \n",
   "+ if",
   "+ not",
   "+ hasattr",
   "+ (",
   "+ FLAGS",
   "+ ,",
   "+ 'test_srcdir'",
   "+ )",
   "+ :",
   "+ \n",
   "+   ",
   "+ FLAGS",
   "+ .",
   "+ test_srcdir",
   "+ =",
   "+ ''",
   "+ \n",
   "+ \n",
   "+ if",
   "+ not",
   "+ hasattr",
   "+ (",
   "+ FLAGS",
   "+ ,",
   "+ 'test_tmpdir'",
   "+ )",
   "+ :",
   "+ \n",
   "+   ",
   "+ FLAGS",
   "+ .",
   "+ test_tmpdir",
   "+ =",
   "+ tf",
   "+ .",
   "+ test",
   "+ .",
   "+ get_temp_dir",
   "+ (",
   "+ )",
   "  \n",
   "          ",
   "  FLAGS",
   "  .",
   "  test_srcdir",
   "  ,",
   "- 'google3/nlp/saft/components/dependencies/'",
   "- \n",
   "- 'opensource/testdata/context.pbtxt'",
   "+ 'neurosis/testdata/context.pbtxt'",
   "+ )",
   "  )",
   "  )",
   "  )",
   "  txt')"
  ]
 },
 {
  "number": 63,
  "commit_len": 51,
  "created_at": "2016-05-12 18:34:12",
  "merged_at": "2016-05-12 18:40:03",
  "merged_by": "martinwicke",
  "1-n_url": "https://github.com/tensorflow/models/compare/6c34cf7a8789500bbf679b761b58bb9b337a8cf1...455cee25a3f9f545abfb795baa2f78aaac318f51.diff",
  "file_path": "syntaxnet/reader_ops_test.py",
  "changes_set": [
   "  writer",
   "  .",
   "  write",
   "  (",
   "  _TokenEmbedding",
   "  (",
   "- 'the'",
   "+ '.'",
   "  ,",
   "  [",
   "  1",
   "  ,",
   "  2",
   "  ]",
   "  )",
   "  )",
   "  \n",
   "      ",
   "  writer",
   "  .",
   "  write",
   "  (",
   "  _TokenEmbedding",
   "  (",
   "- '.'",
   "+ 'the'",
   "  ,",
   "  [",
   "  5",
   "  ,",
   "  6",
   "  ]",
   "  )",
   "  )",
   "  )",
   "  )",
   "   6]))"
  ]
 },
 {
  "number": 63,
  "commit_len": 51,
  "created_at": "2016-05-12 18:34:12",
  "merged_at": "2016-05-12 18:40:03",
  "merged_by": "martinwicke",
  "1-n_url": "https://github.com/tensorflow/models/compare/6c34cf7a8789500bbf679b761b58bb9b337a8cf1...455cee25a3f9f545abfb795baa2f78aaac318f51.diff",
  "file_path": "syntaxnet/structured_graph_builder.py",
  "changes_set": [
   "+ \n",
   "  from",
   "- google3",
   "- .",
   "- third_party",
   "- .",
   "  tensorflow",
   "  .",
   "  python",
   "  .",
   "  ops",
   "  import",
   "  control_flow_ops",
   "  as",
   "  cf",
   "  \n",
   "  from",
   "- google3",
   "- .",
   "- third_party",
   "- .",
   "  tensorflow",
   "  .",
   "  python",
   "  .",
   "  ops",
   "  import",
   "  state_ops",
   "  \n",
   "  from",
   "+ neurosis",
   "- google3",
   "- .",
   "- nlp",
   "- .",
   "- saft",
   "- .",
   "- components",
   "- .",
   "- dependencies",
   "- .",
   "- opensource",
   "  import",
   "  graph_builder",
   "  \n",
   "  from",
   "+ neurosis",
   "- google3",
   "- .",
   "- nlp",
   "- .",
   "- saft",
   "- .",
   "- components",
   "- .",
   "- dependencies",
   "- .",
   "- opensource",
   "  .",
   "  ops",
   "  import",
   "  gen_parser_ops"
  ]
 },
 {
  "number": 155,
  "commit_len": 3,
  "created_at": "2016-05-26 08:16:42",
  "merged_at": "2016-05-31 16:15:14",
  "merged_by": "martinwicke",
  "1-n_url": "https://github.com/tensorflow/models/compare/5ee2a0c8024ee0343f5c69490859184365393da1...a2909725383a2f74fc89a486059495d11919409b.diff",
  "file_path": "transformer/cluttered_mnist.py",
  "changes_set": [
   "- \n",
   "- from",
   "- scipy",
   "- import",
   "- ndimage",
   "- \n",
   "- import",
   "- matplotlib",
   "- .",
   "- pyplot",
   "- as",
   "- plt",
   "  \n",
   "  from",
   "  tf_utils",
   "  import",
   "- conv2d",
   "- ,",
   "- linear",
   "- ,",
   "  weight_variable",
   "  ,",
   "  bias_variable",
   "  ,",
   "  dense_to_one_hot"
  ]
 },
 {
  "number": 155,
  "commit_len": 3,
  "created_at": "2016-05-26 08:16:42",
  "merged_at": "2016-05-31 16:15:14",
  "merged_by": "martinwicke",
  "1-n_url": "https://github.com/tensorflow/models/compare/5ee2a0c8024ee0343f5c69490859184365393da1...a2909725383a2f74fc89a486059495d11919409b.diff",
  "file_path": "transformer/spatial_transformer.py",
  "changes_set": [
   "  U",
   "  :",
   "  float",
   "  \n",
   "          ",
   "  shape",
   "  [",
   "  num_batch",
   "  ,",
   "  height",
   "  ,",
   "  width",
   "  ,",
   "  num_channels",
   "  ]",
   "  .",
   "  \n",
   "   ",
   "  theta",
   "  :",
   "  float",
   "  \n",
   "      ",
   "  out_size",
   "  :",
   "  tuple",
   "  of",
   "  two",
   "- floats",
   "+ ints",
   "  \n",
   "          ",
   "  The",
   "  size",
   "  of",
   "  the",
   "  output",
   "  of",
   "  the",
   "  network",
   "- k",
   "- k",
   "- k",
   "- twork",
   "+ (",
   "+ height",
   "+ ,",
   "+ width",
   "+ )",
   "+ )",
   "+ )",
   "+ )",
   "+ idth)"
  ]
 },
 {
  "number": 155,
  "commit_len": 3,
  "created_at": "2016-05-26 08:16:42",
  "merged_at": "2016-05-31 16:15:14",
  "merged_by": "martinwicke",
  "1-n_url": "https://github.com/tensorflow/models/compare/5ee2a0c8024ee0343f5c69490859184365393da1...a2909725383a2f74fc89a486059495d11919409b.diff",
  "file_path": "transformer/spatial_transformer.py",
  "changes_set": [
   "  [",
   "  0.",
   "  ,",
   "  1.",
   "  ,",
   "  0.",
   "  ]",
   "  ]",
   "  )",
   "  \n",
   "              ",
   "  rep",
   "  =",
   "  tf",
   "  .",
   "  transpose",
   "  (",
   "+ \n",
   "+                 ",
   "  tf",
   "  .",
   "  expand_dims",
   "  (",
   "  tf",
   "  .",
   "  ones",
   "  (",
   "  shape",
   "  =",
   "  tf",
   "  .",
   "  pack",
   "  (",
   "  [",
   "  n_repeats",
   "  ,",
   "  ]",
   "  )",
   "  )",
   "  ,",
   "  1",
   "  )",
   "  ,",
   "  [",
   "  1",
   "  ,",
   "  0",
   "  ]",
   "  )",
   "  \n",
   "+  ",
   "  x",
   "  =",
   "  tf",
   "  .",
   "  matmul",
   "  (",
   "  tf",
   "  .",
   "  reshape",
   "  (",
   "  x",
   "  ,",
   "  (",
   "  -",
   "  1",
   "  ,",
   "  1",
   "  )",
   "  )",
   "  ,",
   "  rep",
   "  )",
   "  \n",
   "  return",
   "  tf",
   "  .",
   "  reshape",
   "  (",
   "  x",
   "  ,",
   "  [",
   "  -",
   "  1",
   "  ]",
   "  )",
   "  )",
   "  )",
   "  [-1])"
  ]
 },
 {
  "number": 155,
  "commit_len": 3,
  "created_at": "2016-05-26 08:16:42",
  "merged_at": "2016-05-31 16:15:14",
  "merged_by": "martinwicke",
  "1-n_url": "https://github.com/tensorflow/models/compare/5ee2a0c8024ee0343f5c69490859184365393da1...a2909725383a2f74fc89a486059495d11919409b.diff",
  "file_path": "transformer/spatial_transformer.py",
  "changes_set": [
   "  wa",
   "  =",
   "  tf",
   "  .",
   "  expand_dims",
   "  (",
   "  (",
   "  (",
   "  x1_f",
   "  -",
   "  x",
   "  )",
   "  *",
   "  (",
   "  y1_f",
   "  -",
   "  y",
   "  )",
   "  )",
   "  ,",
   "  1",
   "  )",
   "  \n",
   "              ",
   "  wb",
   "  =",
   "  tf",
   "  .",
   "  expand_dims",
   "  (",
   "  (",
   "  (",
   "  x1_f",
   "  -",
   "  x",
   "  )",
   "  *",
   "  (",
   "  y",
   "  -",
   "  y0_f",
   "  )",
   "  )",
   "  ,",
   "  1",
   "  )",
   "  \n",
   "  wc",
   "  =",
   "  tf",
   "  .",
   "  expand_dims",
   "  (",
   "  (",
   "  (",
   "  x",
   "  -",
   "  x0_f",
   "  )",
   "  *",
   "  (",
   "  y1_f",
   "  -",
   "  y",
   "  )",
   "  )",
   "  ,",
   "  1",
   "  )",
   "  \n",
   "  wd",
   "  =",
   "  tf",
   "  .",
   "  expand_dims",
   "  (",
   "  (",
   "  (",
   "  x",
   "  -",
   "  x0_f",
   "  )",
   "  *",
   "  (",
   "  y",
   "  -",
   "  y0_f",
   "  )",
   "  )",
   "  ,",
   "  1",
   "  )",
   "  )",
   "  )",
   "- )),1)",
   "+ ), 1)"
  ]
 },
 {
  "number": 155,
  "commit_len": 3,
  "created_at": "2016-05-26 08:16:42",
  "merged_at": "2016-05-31 16:15:14",
  "merged_by": "martinwicke",
  "1-n_url": "https://github.com/tensorflow/models/compare/5ee2a0c8024ee0343f5c69490859184365393da1...a2909725383a2f74fc89a486059495d11919409b.diff",
  "file_path": "transformer/spatial_transformer.py",
  "changes_set": [
   "  tf",
   "  .",
   "  transpose",
   "  (",
   "  tf",
   "  .",
   "  expand_dims",
   "  (",
   "  tf",
   "  .",
   "  linspace",
   "  (",
   "  -",
   "  1.0",
   "  ,",
   "  1.0",
   "  ,",
   "  width",
   "  )",
   "  ,",
   "  1",
   "  )",
   "  ,",
   "  [",
   "  1",
   "  ,",
   "  0",
   "  ]",
   "  )",
   "  )",
   "  \n",
   "              ",
   "  y_t",
   "  =",
   "  tf",
   "  .",
   "  matmul",
   "  (",
   "  tf",
   "  .",
   "  expand_dims",
   "  (",
   "  tf",
   "  .",
   "  linspace",
   "  (",
   "  -",
   "  1.0",
   "  ,",
   "  1.0",
   "  ,",
   "  height",
   "  )",
   "  ,",
   "  1",
   "  )",
   "  ,",
   "  \n",
   "-                         ",
   "+                             ",
   "  tf",
   "  .",
   "  ones",
   "  (",
   "  shape",
   "  =",
   "  tf",
   "  .",
   "  pack",
   "  (",
   "  [",
   "  1",
   "  ,",
   "  width",
   "  ]",
   "  )",
   "  )",
   "  )",
   "  \n",
   "   ",
   "  x_t_flat",
   "  =",
   "  tf",
   "  .",
   "  reshape",
   "  (",
   "  x_t",
   "  ,",
   "  (",
   "  1",
   "  ,",
   "  -",
   "  1",
   "  )",
   "  )",
   "  \n",
   "  y_t_flat",
   "  =",
   "  tf",
   "  .",
   "  reshape",
   "  (",
   "  y_t",
   "  ,",
   "  (",
   "  1",
   "  ,",
   "  -",
   "  1",
   "  )",
   "  )",
   "  )",
   "  )",
   "   -1))"
  ]
 },
 {
  "number": 155,
  "commit_len": 3,
  "created_at": "2016-05-26 08:16:42",
  "merged_at": "2016-05-31 16:15:14",
  "merged_by": "martinwicke",
  "1-n_url": "https://github.com/tensorflow/models/compare/5ee2a0c8024ee0343f5c69490859184365393da1...a2909725383a2f74fc89a486059495d11919409b.diff",
  "file_path": "transformer/spatial_transformer.py",
  "changes_set": [
   "  out_width",
   "  =",
   "  out_size",
   "  [",
   "  1",
   "  ]",
   "  \n",
   "              ",
   "  grid",
   "  =",
   "  tf",
   "  .",
   "  expand_dims",
   "  (",
   "  grid",
   "  ,",
   "  0",
   "  )",
   "  \n",
   "  grid",
   "  =",
   "  tf",
   "  .",
   "  reshape",
   "  (",
   "  grid",
   "  ,",
   "  [",
   "  -",
   "  1",
   "  ]",
   "  )",
   "  \n",
   "  grid",
   "  =",
   "  tf",
   "  .",
   "  tile",
   "  (",
   "  grid",
   "  ,",
   "  tf",
   "  .",
   "  pack",
   "  (",
   "  [",
   "  num_batch",
   "  ]",
   "  )",
   "  )",
   "  \n",
   "  grid",
   "  =",
   "  tf",
   "  .",
   "  reshape",
   "  (",
   "  grid",
   "  ,",
   "  tf",
   "  .",
   "  pack",
   "  (",
   "  [",
   "  num_batch",
   "  ,",
   "  3",
   "  ,",
   "  -",
   "  1",
   "  ]",
   "  )",
   "  )",
   "  \n",
   "  x_s",
   "  =",
   "  tf",
   "  .",
   "  slice",
   "  (",
   "  T_g",
   "  ,",
   "  [",
   "  0",
   "  ,",
   "  0",
   "  ,",
   "  0",
   "  ]",
   "  ,",
   "  [",
   "  -",
   "  1",
   "  ,",
   "  1",
   "  ,",
   "  -",
   "  1",
   "  ]",
   "  )",
   "  \n",
   "  y_s",
   "  =",
   "  tf",
   "  .",
   "  slice",
   "  (",
   "  T_g",
   "  ,",
   "  [",
   "  0",
   "  ,",
   "  1",
   "  ,",
   "  0",
   "  ]",
   "  ,",
   "  [",
   "  -",
   "  1",
   "  ,",
   "  1",
   "  ,",
   "  -",
   "  1",
   "  ]",
   "  )",
   "  \n",
   "  x_s_flat",
   "  =",
   "  tf",
   "  .",
   "  reshape",
   "  (",
   "  x_s",
   "  ,",
   "  [",
   "  -",
   "  1",
   "  ]",
   "  )",
   "  \n",
   "  y_s_flat",
   "  =",
   "  tf",
   "  .",
   "  reshape",
   "  (",
   "  y_s",
   "  ,",
   "  [",
   "  -",
   "  1",
   "  ]",
   "  )",
   "  \n",
   "-                   ",
   "+                 ",
   "  input_dim",
   "  ,",
   "  x_s_flat",
   "  ,",
   "  y_s_flat",
   "  ,",
   "  \n",
   "  out_size",
   "  )",
   "  \n",
   "   ",
   "  output",
   "  =",
   "  tf",
   "  .",
   "  reshape",
   "  (",
   "+ \n",
   "+                 ",
   "  input_transformed",
   "  ,",
   "  tf",
   "  .",
   "  pack",
   "  (",
   "  [",
   "  num_batch",
   "  ,",
   "  out_height",
   "  ,",
   "  out_width",
   "  ,",
   "  num_channels",
   "  ]",
   "  )",
   "  )",
   "  )",
   "  )",
   "+ )",
   "  ls]))"
  ]
 },
 {
  "number": 181,
  "commit_len": 2,
  "created_at": "2016-06-06 09:33:11",
  "merged_at": "2016-06-23 02:37:18",
  "merged_by": "martinwicke",
  "1-n_url": "https://github.com/tensorflow/models/compare/552c75b550820496e4bd3431fc098ba519422fcd...3b44c941796f7f6e5e61f6bdb2b524e08a78a95c.diff",
  "file_path": "transformer/cluttered_mnist.py",
  "changes_set": [
   "  y_logits",
   "  =",
   "- tf",
   "- .",
   "- nn",
   "- .",
   "- softmax",
   "- (",
   "  tf",
   "  .",
   "  matmul",
   "  (",
   "  h_fc1_drop",
   "  ,",
   "  W_fc2",
   "  )",
   "  +",
   "  b_fc2",
   "- )",
   "  \n",
   "  cross_entropy",
   "  =",
   "  tf",
   "  .",
   "- reduce_sum",
   "+ reduce_mean",
   "  ("
  ]
 },
 {
  "number": 306,
  "commit_len": 4,
  "created_at": "2016-08-07 11:57:06",
  "merged_at": "2016-08-07 11:58:03",
  "merged_by": "calberti",
  "1-n_url": "https://github.com/tensorflow/models/compare/42c4a2c53a0f984a561966f914d2b7d65d2dfba6...abebf103bd8c48bf57f5d643bfb650b336e8fbc9.diff",
  "file_path": "syntaxnet/syntaxnet/parser_eval.py",
  "changes_set": [
   "+ def",
   "+ RewriteContext",
   "+ (",
   "+ task_context",
   "+ )",
   "+ :",
   "+ \n",
   "+   ",
   "+ context",
   "+ =",
   "+ task_spec_pb2",
   "+ .",
   "+ TaskSpec",
   "+ (",
   "+ )",
   "+ \n",
   "+ with",
   "+ gfile",
   "+ .",
   "+ FastGFile",
   "+ (",
   "+ task_context",
   "+ )",
   "+ as",
   "+ fin",
   "+ :",
   "+ \n",
   "+     ",
   "+ text_format",
   "+ .",
   "+ Merge",
   "+ (",
   "+ fin",
   "+ .",
   "+ read",
   "+ (",
   "+ )",
   "+ ,",
   "+ context",
   "+ )",
   "+ \n",
   "+  ",
   "+ for",
   "+ resource",
   "+ in",
   "+ context",
   "+ .",
   "+ input",
   "+ :",
   "+ \n",
   "+     ",
   "+ for",
   "+ part",
   "+ in",
   "+ resource",
   "+ .",
   "+ part",
   "+ :",
   "+ \n",
   "+       ",
   "+ if",
   "+ part",
   "+ .",
   "+ file_pattern",
   "+ !=",
   "+ '-'",
   "+ :",
   "+ \n",
   "+         ",
   "+ part",
   "+ .",
   "+ file_pattern",
   "+ =",
   "+ os",
   "+ .",
   "+ path",
   "+ .",
   "+ join",
   "+ (",
   "+ FLAGS",
   "+ .",
   "+ resource_dir",
   "+ ,",
   "+ part",
   "+ .",
   "+ file_pattern",
   "+ )",
   "+ \n",
   "+  ",
   "+  ",
   "+  ",
   "+ with",
   "+ tempfile",
   "+ .",
   "+ NamedTemporaryFile",
   "+ (",
   "+ delete",
   "+ =",
   "+ False",
   "+ )",
   "+ as",
   "+ fout",
   "+ :",
   "+ \n",
   "+     ",
   "+ fout",
   "+ .",
   "+ write",
   "+ (",
   "+ str",
   "+ (",
   "+ context",
   "+ )",
   "+ )",
   "+ \n",
   "+ return",
   "+ fout",
   "+ .",
   "+ name",
   "+ \n",
   "+ \n",
   "+ \n",
   "  def",
   "  Eval",
   "  (",
   "  sess",
   "- ,",
   "- num_actions",
   "- ,",
   "+ )",
   "+ :",
   "+ \n",
   "+   ",
   "+ \"\"\"Builds and evaluates a network.\"\"\"",
   "+ \n",
   "+ task_context",
   "+ =",
   "+ FLAGS",
   "+ .",
   "+ task_context",
   "+ \n",
   "+ if",
   "+ FLAGS",
   "+ .",
   "+ resource_dir",
   "+ :",
   "+ \n",
   "+     ",
   "+ task_context",
   "+ =",
   "+ RewriteContext",
   "+ (",
   "+ task_context",
   "+ )",
   "+ \n",
   "+  ",
   "  feature_sizes",
   "  ,",
   "  domain_sizes",
   "  ,",
   "  embedding_dims",
   "+ ,",
   "+ num_actions",
   "+ =",
   "+ sess",
   "+ .",
   "+ run",
   "+ (",
   "+ gen_parser_ops",
   "+ .",
   "+ feature_size",
   "+ (",
   "+ task_context",
   "+ =",
   "+ task_context",
   "+ ,",
   "+ arg_prefix",
   "+ =",
   "+ FLAGS",
   "+ .",
   "+ arg_prefix",
   "  )",
   "+ )",
   "+ )",
   "+ )",
   "+ fix))",
   "- :",
   "- \n",
   "-   ",
   "- \"\"\"Builds and evaluates a network.\n  Args:\n    sess: tensorflow session to use\n    num_actions: number of possible golden actions\n    feature_sizes: size of each feature vector\n    domain_sizes: number of possible feature ids in each feature vector\n    embedding_dims: embedding dimension for each feature group\n  \"\"\"",
   "- \"",
   "- \"",
   "-   \"\"\""
  ]
 },
 {
  "number": 306,
  "commit_len": 4,
  "created_at": "2016-08-07 11:57:06",
  "merged_at": "2016-08-07 11:58:03",
  "merged_by": "calberti",
  "1-n_url": "https://github.com/tensorflow/models/compare/42c4a2c53a0f984a561966f914d2b7d65d2dfba6...abebf103bd8c48bf57f5d643bfb650b336e8fbc9.diff",
  "file_path": "syntaxnet/syntaxnet/parser_eval.py",
  "changes_set": [
   "  task_context",
   "  =",
   "- FLAGS",
   "- .",
   "  task_context",
   "  ,"
  ]
 },
 {
  "number": 306,
  "commit_len": 4,
  "created_at": "2016-08-07 11:57:06",
  "merged_at": "2016-08-07 11:58:03",
  "merged_by": "calberti",
  "1-n_url": "https://github.com/tensorflow/models/compare/42c4a2c53a0f984a561966f914d2b7d65d2dfba6...abebf103bd8c48bf57f5d643bfb650b336e8fbc9.diff",
  "file_path": "syntaxnet/syntaxnet/parser_eval.py",
  "changes_set": [
   "- feature_sizes",
   "- ,",
   "- domain_sizes",
   "- ,",
   "- embedding_dims",
   "- ,",
   "- num_actions",
   "- =",
   "- sess",
   "- .",
   "- run",
   "- (",
   "- gen_parser_ops",
   "- .",
   "- feature_size",
   "- (",
   "- task_context",
   "- =",
   "- FLAGS",
   "- .",
   "- task_context",
   "- ,",
   "- arg_prefix",
   "- =",
   "- FLAGS",
   "- .",
   "- arg_prefix",
   "- )",
   "- )",
   "- \n",
   "-   ",
   "- with",
   "- tf",
   "- .",
   "- Session",
   "- (",
   "- )",
   "- as",
   "- sess",
   "- :",
   "- \n",
   "-     ",
   "  Eval",
   "  (",
   "  sess",
   "- ,",
   "- num_actions",
   "- ,",
   "- feature_sizes",
   "- ,",
   "- domain_sizes",
   "- ,",
   "- embedding_dims",
   "  )",
   "- )",
   "- )",
   "- )",
   "- dims)"
  ]
 },
 {
  "number": 308,
  "commit_len": 7,
  "created_at": "2016-08-08 15:38:03",
  "merged_at": "2016-08-08 15:38:47",
  "merged_by": "calberti",
  "1-n_url": "https://github.com/tensorflow/models/compare/42c4a2c53a0f984a561966f914d2b7d65d2dfba6...adf3eddb097a4e7c00df5cc476eb691f16901181.diff",
  "file_path": "syntaxnet/syntaxnet/parser_eval.py",
  "changes_set": [
   "+ def",
   "+ RewriteContext",
   "+ (",
   "+ task_context",
   "+ )",
   "+ :",
   "+ \n",
   "+   ",
   "+ context",
   "+ =",
   "+ task_spec_pb2",
   "+ .",
   "+ TaskSpec",
   "+ (",
   "+ )",
   "+ \n",
   "+ with",
   "+ gfile",
   "+ .",
   "+ FastGFile",
   "+ (",
   "+ task_context",
   "+ )",
   "+ as",
   "+ fin",
   "+ :",
   "+ \n",
   "+     ",
   "+ text_format",
   "+ .",
   "+ Merge",
   "+ (",
   "+ fin",
   "+ .",
   "+ read",
   "+ (",
   "+ )",
   "+ ,",
   "+ context",
   "+ )",
   "+ \n",
   "+  ",
   "+ for",
   "+ resource",
   "+ in",
   "+ context",
   "+ .",
   "+ input",
   "+ :",
   "+ \n",
   "+     ",
   "+ for",
   "+ part",
   "+ in",
   "+ resource",
   "+ .",
   "+ part",
   "+ :",
   "+ \n",
   "+       ",
   "+ if",
   "+ part",
   "+ .",
   "+ file_pattern",
   "+ !=",
   "+ '-'",
   "+ :",
   "+ \n",
   "+         ",
   "+ part",
   "+ .",
   "+ file_pattern",
   "+ =",
   "+ os",
   "+ .",
   "+ path",
   "+ .",
   "+ join",
   "+ (",
   "+ FLAGS",
   "+ .",
   "+ resource_dir",
   "+ ,",
   "+ part",
   "+ .",
   "+ file_pattern",
   "+ )",
   "+ \n",
   "+  ",
   "+  ",
   "+  ",
   "+ with",
   "+ tempfile",
   "+ .",
   "+ NamedTemporaryFile",
   "+ (",
   "+ delete",
   "+ =",
   "+ False",
   "+ )",
   "+ as",
   "+ fout",
   "+ :",
   "+ \n",
   "+     ",
   "+ fout",
   "+ .",
   "+ write",
   "+ (",
   "+ str",
   "+ (",
   "+ context",
   "+ )",
   "+ )",
   "+ \n",
   "+ return",
   "+ fout",
   "+ .",
   "+ name",
   "+ \n",
   "+ \n",
   "+ \n",
   "  def",
   "  Eval",
   "  (",
   "  sess",
   "- ,",
   "- num_actions",
   "- ,",
   "+ )",
   "+ :",
   "+ \n",
   "+   ",
   "+ \"\"\"Builds and evaluates a network.\"\"\"",
   "+ \n",
   "+ task_context",
   "+ =",
   "+ FLAGS",
   "+ .",
   "+ task_context",
   "+ \n",
   "+ if",
   "+ FLAGS",
   "+ .",
   "+ resource_dir",
   "+ :",
   "+ \n",
   "+     ",
   "+ task_context",
   "+ =",
   "+ RewriteContext",
   "+ (",
   "+ task_context",
   "+ )",
   "+ \n",
   "+  ",
   "  feature_sizes",
   "  ,",
   "  domain_sizes",
   "  ,",
   "  embedding_dims",
   "+ ,",
   "+ num_actions",
   "+ =",
   "+ sess",
   "+ .",
   "+ run",
   "+ (",
   "+ gen_parser_ops",
   "+ .",
   "+ feature_size",
   "+ (",
   "+ task_context",
   "+ =",
   "+ task_context",
   "+ ,",
   "+ arg_prefix",
   "+ =",
   "+ FLAGS",
   "+ .",
   "+ arg_prefix",
   "  )",
   "+ )",
   "+ )",
   "+ )",
   "+ fix))",
   "- :",
   "- \n",
   "-   ",
   "- \"\"\"Builds and evaluates a network.\n  Args:\n    sess: tensorflow session to use\n    num_actions: number of possible golden actions\n    feature_sizes: size of each feature vector\n    domain_sizes: number of possible feature ids in each feature vector\n    embedding_dims: embedding dimension for each feature group\n  \"\"\"",
   "- \"",
   "- \"",
   "-   \"\"\""
  ]
 },
 {
  "number": 308,
  "commit_len": 7,
  "created_at": "2016-08-08 15:38:03",
  "merged_at": "2016-08-08 15:38:47",
  "merged_by": "calberti",
  "1-n_url": "https://github.com/tensorflow/models/compare/42c4a2c53a0f984a561966f914d2b7d65d2dfba6...adf3eddb097a4e7c00df5cc476eb691f16901181.diff",
  "file_path": "syntaxnet/syntaxnet/parser_eval.py",
  "changes_set": [
   "  task_context",
   "  =",
   "- FLAGS",
   "- .",
   "  task_context",
   "  ,"
  ]
 },
 {
  "number": 308,
  "commit_len": 7,
  "created_at": "2016-08-08 15:38:03",
  "merged_at": "2016-08-08 15:38:47",
  "merged_by": "calberti",
  "1-n_url": "https://github.com/tensorflow/models/compare/42c4a2c53a0f984a561966f914d2b7d65d2dfba6...adf3eddb097a4e7c00df5cc476eb691f16901181.diff",
  "file_path": "syntaxnet/syntaxnet/parser_eval.py",
  "changes_set": [
   "- feature_sizes",
   "- ,",
   "- domain_sizes",
   "- ,",
   "- embedding_dims",
   "- ,",
   "- num_actions",
   "- =",
   "- sess",
   "- .",
   "- run",
   "- (",
   "- gen_parser_ops",
   "- .",
   "- feature_size",
   "- (",
   "- task_context",
   "- =",
   "- FLAGS",
   "- .",
   "- task_context",
   "- ,",
   "- arg_prefix",
   "- =",
   "- FLAGS",
   "- .",
   "- arg_prefix",
   "- )",
   "- )",
   "- \n",
   "-   ",
   "- with",
   "- tf",
   "- .",
   "- Session",
   "- (",
   "- )",
   "- as",
   "- sess",
   "- :",
   "- \n",
   "-     ",
   "  Eval",
   "  (",
   "  sess",
   "- ,",
   "- num_actions",
   "- ,",
   "- feature_sizes",
   "- ,",
   "- domain_sizes",
   "- ,",
   "- embedding_dims",
   "  )",
   "- )",
   "- )",
   "- )",
   "- dims)"
  ]
 },
 {
  "number": 349,
  "commit_len": 2,
  "created_at": "2016-08-27 00:20:54",
  "merged_at": "2016-08-27 00:29:45",
  "merged_by": "martinwicke",
  "1-n_url": "https://github.com/tensorflow/models/compare/5e45908744c76caadfaee0da278632231ba4cfef...03d7dce753c5234387c9c27e2b8eb0b401915f97.diff",
  "file_path": "syntaxnet/syntaxnet/conll2tree.py",
  "changes_set": [
   "+ Note",
   "+ that",
   "+ the",
   "+ suffix",
   "+ \"@id\"",
   "+ (",
   "+ where",
   "+ 'id'",
   "+ is",
   "+ a",
   "+ number",
   "+ )",
   "+ is",
   "+ appended",
   "+ to",
   "+ each",
   "+ element",
   "+ \n",
   "+      ",
   "+ to",
   "+ handle",
   "+ the",
   "+ sentence",
   "+ that",
   "+ has",
   "+ multiple",
   "+ elements",
   "+ with",
   "+ identical",
   "+ representation",
   "+ .",
   "+ \n",
   "+ Those",
   "+ suffix",
   "+ needs",
   "+ to",
   "+ be",
   "+ removed",
   "+ after",
   "+ the",
   "+ asciitree",
   "+ is",
   "+ rendered",
   "+ .",
   "+ \n",
   "+  ",
   "  token_str",
   "  =",
   "- [",
   "+ list",
   "+ (",
   "+ )",
   "+ \n",
   "+     ",
   "+ token_str",
   "+ .",
   "+ append",
   "+ (",
   "- '%s %s %s'",
   "+ '%s %s %s @%d'",
   "  %",
   "  (",
   "  token",
   "  .",
   "  word",
   "  ,",
   "  token",
   "  .",
   "  tag",
   "  ,",
   "  token",
   "  .",
   "  label",
   "+ ,",
   "+ (",
   "+ i",
   "+ +",
   "+ 1",
   "  )",
   "+ )",
   "+ )",
   "+ )",
   "+ )",
   "+ +1)))",
   "- for",
   "- token",
   "- in",
   "- sentence",
   "- .",
   "- token",
   "- ]"
  ]
 },
 {
  "number": 349,
  "commit_len": 2,
  "created_at": "2016-08-27 00:20:54",
  "merged_at": "2016-08-27 00:29:45",
  "merged_by": "martinwicke",
  "1-n_url": "https://github.com/tensorflow/models/compare/5e45908744c76caadfaee0da278632231ba4cfef...03d7dce753c5234387c9c27e2b8eb0b401915f97.diff",
  "file_path": "syntaxnet/syntaxnet/conll2tree.py",
  "changes_set": [
   "- print",
   "+ tr_str",
   "+ =",
   "  tr",
   "  (",
   "  d",
   "  )",
   "+ \n",
   "+         ",
   "+ pat",
   "+ =",
   "+ re",
   "+ .",
   "+ compile",
   "+ (",
   "+ '\\s*@\\d+$'",
   "+ )",
   "+ \n",
   "+ for",
   "+ tr_ln",
   "+ in",
   "+ tr_str",
   "+ .",
   "+ splitlines",
   "+ (",
   "+ )",
   "+ :",
   "+ \n",
   "+           ",
   "+ print",
   "+ pat",
   "+ .",
   "+ sub",
   "+ (",
   "+ ''",
   "+ ,",
   "+ tr_ln",
   "+ )",
   "+ )",
   "+ )",
   "+ )",
   "+ r_ln)"
  ]
 },
 {
  "number": 349,
  "commit_len": 2,
  "created_at": "2016-08-27 00:20:54",
  "merged_at": "2016-08-27 00:29:45",
  "merged_by": "martinwicke",
  "1-n_url": "https://github.com/tensorflow/models/compare/5e45908744c76caadfaee0da278632231ba4cfef...03d7dce753c5234387c9c27e2b8eb0b401915f97.diff",
  "file_path": "syntaxnet/syntaxnet/parser_eval.py",
  "changes_set": [
   "+ def",
   "+ RewriteContext",
   "+ (",
   "+ task_context",
   "+ )",
   "+ :",
   "+ \n",
   "+   ",
   "+ context",
   "+ =",
   "+ task_spec_pb2",
   "+ .",
   "+ TaskSpec",
   "+ (",
   "+ )",
   "+ \n",
   "+ with",
   "+ gfile",
   "+ .",
   "+ FastGFile",
   "+ (",
   "+ task_context",
   "+ )",
   "+ as",
   "+ fin",
   "+ :",
   "+ \n",
   "+     ",
   "+ text_format",
   "+ .",
   "+ Merge",
   "+ (",
   "+ fin",
   "+ .",
   "+ read",
   "+ (",
   "+ )",
   "+ ,",
   "+ context",
   "+ )",
   "+ \n",
   "+  ",
   "+ for",
   "+ resource",
   "+ in",
   "+ context",
   "+ .",
   "+ input",
   "+ :",
   "+ \n",
   "+     ",
   "+ for",
   "+ part",
   "+ in",
   "+ resource",
   "+ .",
   "+ part",
   "+ :",
   "+ \n",
   "+       ",
   "+ if",
   "+ part",
   "+ .",
   "+ file_pattern",
   "+ !=",
   "+ '-'",
   "+ :",
   "+ \n",
   "+         ",
   "+ part",
   "+ .",
   "+ file_pattern",
   "+ =",
   "+ os",
   "+ .",
   "+ path",
   "+ .",
   "+ join",
   "+ (",
   "+ FLAGS",
   "+ .",
   "+ resource_dir",
   "+ ,",
   "+ part",
   "+ .",
   "+ file_pattern",
   "+ )",
   "+ \n",
   "+  ",
   "+  ",
   "+  ",
   "+ with",
   "+ tempfile",
   "+ .",
   "+ NamedTemporaryFile",
   "+ (",
   "+ delete",
   "+ =",
   "+ False",
   "+ )",
   "+ as",
   "+ fout",
   "+ :",
   "+ \n",
   "+     ",
   "+ fout",
   "+ .",
   "+ write",
   "+ (",
   "+ str",
   "+ (",
   "+ context",
   "+ )",
   "+ )",
   "+ \n",
   "+ return",
   "+ fout",
   "+ .",
   "+ name",
   "+ \n",
   "+ \n",
   "+ \n",
   "  def",
   "  Eval",
   "  (",
   "  sess",
   "- ,",
   "- num_actions",
   "- ,",
   "+ )",
   "+ :",
   "+ \n",
   "+   ",
   "+ \"\"\"Builds and evaluates a network.\"\"\"",
   "+ \n",
   "+ task_context",
   "+ =",
   "+ FLAGS",
   "+ .",
   "+ task_context",
   "+ \n",
   "+ if",
   "+ FLAGS",
   "+ .",
   "+ resource_dir",
   "+ :",
   "+ \n",
   "+     ",
   "+ task_context",
   "+ =",
   "+ RewriteContext",
   "+ (",
   "+ task_context",
   "+ )",
   "+ \n",
   "+  ",
   "  feature_sizes",
   "  ,",
   "  domain_sizes",
   "  ,",
   "  embedding_dims",
   "+ ,",
   "+ num_actions",
   "+ =",
   "+ sess",
   "+ .",
   "+ run",
   "+ (",
   "+ gen_parser_ops",
   "+ .",
   "+ feature_size",
   "+ (",
   "+ task_context",
   "+ =",
   "+ task_context",
   "+ ,",
   "+ arg_prefix",
   "+ =",
   "+ FLAGS",
   "+ .",
   "+ arg_prefix",
   "  )",
   "+ )",
   "+ )",
   "+ )",
   "+ fix))",
   "- :",
   "- \n",
   "-   ",
   "- \"\"\"Builds and evaluates a network.\n  Args:\n    sess: tensorflow session to use\n    num_actions: number of possible golden actions\n    feature_sizes: size of each feature vector\n    domain_sizes: number of possible feature ids in each feature vector\n    embedding_dims: embedding dimension for each feature group\n  \"\"\"",
   "- \"",
   "- \"",
   "-   \"\"\""
  ]
 },
 {
  "number": 349,
  "commit_len": 2,
  "created_at": "2016-08-27 00:20:54",
  "merged_at": "2016-08-27 00:29:45",
  "merged_by": "martinwicke",
  "1-n_url": "https://github.com/tensorflow/models/compare/5e45908744c76caadfaee0da278632231ba4cfef...03d7dce753c5234387c9c27e2b8eb0b401915f97.diff",
  "file_path": "syntaxnet/syntaxnet/parser_eval.py",
  "changes_set": [
   "  task_context",
   "  =",
   "- FLAGS",
   "- .",
   "  task_context",
   "  ,"
  ]
 },
 {
  "number": 349,
  "commit_len": 2,
  "created_at": "2016-08-27 00:20:54",
  "merged_at": "2016-08-27 00:29:45",
  "merged_by": "martinwicke",
  "1-n_url": "https://github.com/tensorflow/models/compare/5e45908744c76caadfaee0da278632231ba4cfef...03d7dce753c5234387c9c27e2b8eb0b401915f97.diff",
  "file_path": "syntaxnet/syntaxnet/parser_eval.py",
  "changes_set": [
   "- feature_sizes",
   "- ,",
   "- domain_sizes",
   "- ,",
   "- embedding_dims",
   "- ,",
   "- num_actions",
   "- =",
   "- sess",
   "- .",
   "- run",
   "- (",
   "- gen_parser_ops",
   "- .",
   "- feature_size",
   "- (",
   "- task_context",
   "- =",
   "- FLAGS",
   "- .",
   "- task_context",
   "- ,",
   "- arg_prefix",
   "- =",
   "- FLAGS",
   "- .",
   "- arg_prefix",
   "- )",
   "- )",
   "- \n",
   "-   ",
   "- with",
   "- tf",
   "- .",
   "- Session",
   "- (",
   "- )",
   "- as",
   "- sess",
   "- :",
   "- \n",
   "-     ",
   "  Eval",
   "  (",
   "  sess",
   "- ,",
   "- num_actions",
   "- ,",
   "- feature_sizes",
   "- ,",
   "- domain_sizes",
   "- ,",
   "- embedding_dims",
   "  )",
   "- )",
   "- )",
   "- )",
   "- dims)"
  ]
 },
 {
  "number": 377,
  "commit_len": 2,
  "created_at": "2016-08-31 09:07:08",
  "merged_at": "2016-10-17 23:09:45",
  "merged_by": "panyx0718",
  "1-n_url": "https://github.com/tensorflow/models/compare/dab1517e74a082a7af04c7a2b2d75f2e933dc50c...a0de5ca9364f98aa36241c5ea7e891e2f1e1d80b.diff",
  "file_path": "textsum/seq2seq_attention.py",
  "changes_set": [
   "  sess",
   "  =",
   "  sv",
   "  .",
   "  prepare_or_wait_for_session",
   "  (",
   "+ config",
   "+ =",
   "+ tf",
   "+ .",
   "+ ConfigProto",
   "+ (",
   "+ allow_soft_placement",
   "+ =",
   "+ True",
   "  )",
   "+ )"
  ]
 }
]